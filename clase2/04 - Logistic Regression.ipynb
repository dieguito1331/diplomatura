{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **Regresión Logística** se encuentra implementada en dos liberías. La primera es la que venimos utilizando hasta el día de hoy. Es Scikit-Learn. No obstante, en dicha librería no existe implementada la inferencia estadística. Es decir, si queremos calcular el p-value de cada una de las variables para saber si alguna variable es o no relevante en el modelo. Esto no se encuentra desarrollado. Por lo tanto se deberá crear una función específica para poder calcularlo.\n",
    "\n",
    "Otra librería en donde se encuentra implementada es la statsmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/titanic/02 - preprocesada/train.csv\")\n",
    "X = train.drop(columns = [\"Survived\", \"PassengerId\"])\n",
    "y = train.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_pvalue(model, x):\n",
    "    \"\"\" Calculate z-scores for scikit-learn LogisticRegression.\n",
    "    parameters:\n",
    "        model: fitted sklearn.linear_model.LogisticRegression with intercept and large C\n",
    "        x:     matrix on which the model was fit\n",
    "    This function uses asymtptics for maximum likelihood estimates.\n",
    "    \"\"\"\n",
    "    p = model.predict_proba(x)\n",
    "    n = len(p)\n",
    "    m = len(model.coef_[0]) + 1\n",
    "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
    "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
    "    ans = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
    "    vcov = np.linalg.inv(np.matrix(ans))\n",
    "    se = np.sqrt(np.diag(vcov))\n",
    "    t =  coefs/se  \n",
    "    p = (1 - norm.cdf(abs(t))) * 2\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999992 0.69887102 0.00151742 0.06028421 0.11725727        nan\n",
      "        nan        nan 0.99999977        nan 0.99999983 1.\n",
      " 0.99999987 0.99999993 0.99999991 0.99999999 0.99999998 0.99999999\n",
      " 1.         1.         0.99999999 1.         0.99999998 1.\n",
      " 0.99999998 1.         0.03097363]\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train.drop(columns=[\"titulo_Royalty\"])\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "print(logit_pvalue(model, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347619\n",
      "         Iterations 22\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  295\n",
      "Model:                          Logit   Df Residuals:                      272\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Sat, 29 Aug 2020   Pseudo R-squ.:                  0.4855\n",
      "Time:                        23:53:49   Log-Likelihood:                -102.55\n",
      "converged:                       True   LL-Null:                       -199.32\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.072e-29\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Age                     -0.1494      0.068     -2.210      0.027      -0.282      -0.017\n",
      "SibSp                   -0.7875      0.276     -2.854      0.004      -1.328      -0.247\n",
      "Parch                   -0.3010      0.263     -1.145      0.252      -0.816       0.214\n",
      "Fare                    -0.0034      0.006     -0.601      0.548      -0.014       0.008\n",
      "Pclass_1                 5.6047        nan        nan        nan         nan         nan\n",
      "Pclass_2                 2.2760        nan        nan        nan         nan         nan\n",
      "Pclass_3                 1.7596        nan        nan        nan         nan         nan\n",
      "Sex_female              27.3279        nan        nan        nan         nan         nan\n",
      "Sex_male               -16.1947   1.63e+07  -9.92e-07      1.000    -3.2e+07     3.2e+07\n",
      "titulo_Master           17.7669        nan        nan        nan         nan         nan\n",
      "titulo_Miss            -25.0383        nan        nan        nan         nan         nan\n",
      "titulo_Mr               14.6364        nan        nan        nan         nan         nan\n",
      "titulo_Mrs             -24.4843        nan        nan        nan         nan         nan\n",
      "titulo_Officer          15.0584        nan        nan        nan         nan         nan\n",
      "titulo_Royalty          14.8983        nan        nan        nan         nan         nan\n",
      "decilesEdad_0           -0.7190   4.21e+06  -1.71e-07      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_1           -0.0949   4.21e+06  -2.26e-08      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_2            0.2517   4.21e+06   5.98e-08      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_3            0.2689   4.21e+06   6.39e-08      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_4            0.3337   4.21e+06   7.93e-08      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_5            1.9950   4.21e+06   4.74e-07      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_6            1.1981   4.21e+06   2.85e-07      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_7            1.9991   4.21e+06   4.75e-07      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_8            1.9307   4.21e+06   4.59e-07      1.000   -8.24e+06    8.24e+06\n",
      "decilesEdad_9            3.7564   4.21e+06   8.93e-07      1.000   -8.24e+06    8.24e+06\n",
      "labelEncoderEmbarked     0.1869      0.257      0.728      0.466      -0.316       0.690\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_test,X_test.astype(float))\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_male\n",
       "0    108\n",
       "1    187\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.groupby(\"Sex_male\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20814040848186624"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.titulo_Master.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2937577215096096"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
